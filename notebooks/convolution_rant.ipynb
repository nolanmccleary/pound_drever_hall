{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba8a29e",
   "metadata": {},
   "source": [
    "# Convolution Rant\n",
    "\n",
    "I should be doing homework right now but I got sidetracked thinking about how to think about convolution better, went on a run to think about it more deeply, came back, and now I wanna write this down before I get hungry and forget.\n",
    "\n",
    "Say we have two functions, $x(t)$ and $h(t)$. We want to find a function that quantifies the overlap between x and h i.e. if x > 0 and h > 0 or x < 0 when h < 0 we have a positive contribution to our overlap, when x > 0 and h < 0 or vice versa we have a negative contribution to our overlap. \n",
    "\n",
    "We can give one such expression for this as follows:\n",
    "\n",
    "$$\n",
    "R = \\int_{-\\infty}^\\infty x(t)h(t)dt\n",
    "$$\n",
    "\n",
    "This will capture all overlap between the functions. We can also add an offset between the two functions to parameterize R as a function of that offset.\n",
    "\n",
    "$$\n",
    "R(\\tau) = \\int_{-\\infty}^\\infty x(t)h(t + \\tau)dt\n",
    "$$\n",
    "\n",
    "We could also define as follows:\n",
    "\n",
    "$$\n",
    "R(\\tau) = \\int_{-\\infty}^\\infty x(t + \\tau)h(t)dt\n",
    "$$\n",
    "\n",
    "We could also sign flip tau to get a different expression. None of these specifics matter because we are encoding the exact same information and it's all by convention anyway. The important thing is that we are encoding overlap as a function of offset.\n",
    "\n",
    "If our integral is still dependent on t, then R is dependent on both absolute time and tau i.e. $R(t, \\tau)$. This means our correlation is time-variant. If it isn't, then it's time invariant.\n",
    "\n",
    "Say we wanted to find $\\frac{dR}{d\\tau}$, the first thing we can do to simplify our problem is represent our inner product:\n",
    "$$\n",
    "A(t, \\tau) = x(t)h(t+\\tau)\n",
    "$$\n",
    "\n",
    "Geometrically, you can think of any point along $A(t, \\tau)$ as a rectangle where one side is the value of $x(t)$ and the other side is the value of $h(t + \\tau)$. We can then approximate A by breaking it up into m points along the time axis via point function $P(n) n \\rightarrow t$. $A(k)$ is then the value of $A$ at time $t = P(k)$. From here, we can generate a Riemann sum where the kth rectangle's height is $A(P(k))$ and the width for any rectangle r is $P(r+1) - P(r)$, which is assumed to be constant. This means that the area under the curve $A(t, \\tau)$ is really just an infinite series of rectangles with height $A(P(k))$ and width $\\Delta P$. If we were to change tau slightly, we could approximate how R is effected by summing all the area differences across all rectangles. From here, it's intuitive to see that if we were to define a new Riemann sum where the height of each rectangle is equal to $\\frac{dA(k)}{d\\tau}$, this Riemann sum would converge to $\\frac{dR(\\tau)}{d\\tau}$.\n",
    "\n",
    "We now focus on $\\frac{dR}{d\\tau}$. A(t) at any given point in time t is really just the product of $x(t)$ and $h(t + \\tau)$. Forget how offset tau is represented for the moment. Forget you know how to do algebra too for good measure. Imagine you have two functions overlapping at a point. You should be able to convince yourself that if you move one function to the right at any point, the overall 'rectangle area change' expressed by that point will be the same as if you moved the other function to the left by the same amount (remember this directional dichotomy). This is because in both cases the same two parts of the curves will be overlapping, and thus will multiply to the same 'new area' value. We can then ask \"how does this area change when I freeze one function in place and slide the other?\". From here, it's intuitive that the instantaneous rate of area change $\\frac{dA}{d\\tau}$ is equal to the value of the 'fixed' function $x(t)$ multiplied by $\\frac{dh}{d\\tau}$. Pretend $h(\\tau)$ is a plane, standing still at point t and sliding the plane $\\tau$ steps under us would give a vertical difference equal to if we walked along the plane + $\\tau$ steps along the horizontal axis. It would also be the negative value of our drop if we walked $-\\tau$ steps back along the horizontal axis. Thus we can say $\\frac{dh}{d\\tau} = \\frac{dh}{dt}$. By extension of what we said earlier, we can also say $\\frac{dh}{d\\tau}x(t) = -\\frac{dx}{d\\tau}h(t)$ if we were to slide x instead of h. If we were sliding both out in opposite directions then we would say:\n",
    "\n",
    "$$\\frac{dA}{d\\tau} = \\frac{dh(t)}{d\\tau}x(t) + \\frac{dx(t)}{d\\tau}h(t) = \\frac{dh(t)}{dt}x(t) + \\frac{dx(t)}{dt}h(t)$$\n",
    "\n",
    "Which provides some nice geometric intuition for the product rule.\n",
    "\n",
    "\n",
    "This is all to say that:\n",
    "\n",
    "$$\n",
    "\\frac{dR(\\tau)}{d\\tau} = \\int_{-\\infty}^\\infty x(t)\\frac{dh(t + \\tau)}{dt}dt = -\\int_{-\\infty}^\\infty \\frac{dx(t + \\tau)}{dt}h(t)dt\n",
    "$$\n",
    "\n",
    "\n",
    "Here, the negative sign in the second expression results from the directional dichotomy (TM) listed above.\n",
    "\n",
    "We can think of the function $A(t)$ as being approximately composed of a bunch of rectangles, each with height $x(P(t))h(P(t))$ and width p, where p is very small. Let $B(t) = x(P(t))h(P(t))$. Now we would like to grab the value $A(t)$ at some particular $t=\\tau$. We want to find $A(\\tau)$, but the best thing we have is a rectangle of height $B(\\tau)$ and width p, where $B(\\tau) = x(P(\\tau))h(P(\\tau))$, which can be assumed to be the nearest valid point to the left of tau. As p decreases, the number of rectangles increases, and $B(t)$ gets closer and closer to A(t) such that:\n",
    "$$\n",
    "\\lim_{n\\rightarrow\\infty}B(\\tau) = A(\\tau)\n",
    "$$\n",
    "\n",
    "But for now we will assume that p is just very small.\n",
    "\n",
    "We naively think to ourselves that one way we could get $B(\\tau)$ for some time $\\tau$ is to take a function with a value equal to $\\frac{1}{p}$ at exactly $t=\\tau$ and zero everywhere else, the mutliply that function with. A reasonable way to approximate this would be the following:\n",
    "$$\n",
    "\\delta_p(t-\\tau) =\n",
    "\\begin{cases}\n",
    "\\dfrac{1}{p} \\exp\\!\\left(-\\dfrac{t-\\tau}{p}\\right), & t \\ge \\tau, \\\\[8pt]\n",
    "0, & t < \\tau.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Basically just a highly aggressive decaying exponential with some x-offset to the right. Then:\n",
    "\n",
    "$$\n",
    "A(\\tau) = \\lim_{p\\rightarrow 0}\\int_{-\\infty}^{\\infty}B(t)\\delta_p(t-\\tau)dt = \\lim_{p\\rightarrow 0}\\int_{\\tau}^{\\infty}B(t)\\delta_p(t-\\tau)dt \\approx \\lim_{p\\rightarrow 0}\\int_{\\tau}^{\\tau + p}B(t)\\delta_p(t-\\tau) = A(\\tau)[1 - e^{-1}]\n",
    "$$\n",
    "\n",
    "We don't care about anything after $\\tau + p$ because at that point we're on a new rectangle. We also know that for any p the integral will equal $A(\\tau)[1 - e^{-1}]$, so we can just divide this constant out. That means the convergent behaviour of this integral as p approaches zero is $B(\\tau)[1-e^{-1}]$, from which $B(\\tau)$ can be trivially obtained. Thus:\n",
    "\n",
    "$$\n",
    "A(\\tau) = \\lim_{p\\rightarrow 0}\\frac{1}{1-e^{-1}}\\int_{\\tau}^{\\tau + p}B(t)\\delta_p(t-\\tau)dt\n",
    "$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
